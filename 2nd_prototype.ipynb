{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPue21VLd4F+tbGDh7qTFGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aadarsh-1210/hackathon/blob/main/2nd_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyQt5 opencv-python torch\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QPushButton, QVBoxLayout, QHBoxLayout, QWidget, QFileDialog, QListWidget\n",
        "from PyQt5.QtGui import QPixmap, QImage, QPainter, QPen\n",
        "from PyQt5.QtCore import Qt, QRect\n",
        "\n",
        "# Step 1: Load the image using OpenCV, displaying it in the GUI\n",
        "class LabelMaster(QMainWindow):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.setWindowTitle(\"Label Master\")\n",
        "        self.setGeometry(100, 100, 1000, 800)\n",
        "\n",
        "        self.central_widget = QWidget()\n",
        "        self.setCentralWidget(self.central_widget)\n",
        "        self.layout = QHBoxLayout(self.central_widget)\n",
        "\n",
        "        self.image_label = QLabel(self)\n",
        "        self.image_label.setAlignment(Qt.AlignCenter)\n",
        "        self.layout.addWidget(self.image_label, 3)\n",
        "\n",
        "        self.sidebar = QWidget()\n",
        "        self.sidebar_layout = QVBoxLayout(self.sidebar)\n",
        "        self.layout.addWidget(self.sidebar, 1)\n",
        "\n",
        "        self.load_button = QPushButton(\"Load Image\", self)\n",
        "        self.load_button.clicked.connect(self.load_image)\n",
        "        self.sidebar_layout.addWidget(self.load_button)\n",
        "\n",
        "        self.detect_button = QPushButton(\"Detect Objects\", self)\n",
        "        self.detect_button.clicked.connect(self.detect_objects)\n",
        "        self.sidebar_layout.addWidget(self.detect_button)\n",
        "\n",
        "        self.annotation_list = QListWidget(self)\n",
        "        self.sidebar_layout.addWidget(self.annotation_list)\n",
        "\n",
        "        self.export_button = QPushButton(\"Export Annotations\", self)\n",
        "        self.export_button.clicked.connect(self.export_annotations)\n",
        "        self.sidebar_layout.addWidget(self.export_button)\n",
        "\n",
        "        self.current_image = None\n",
        "        self.annotations = []\n",
        "        self.model = self.load_yolo_model()\n",
        "\n",
        "\n",
        "    # ... (other methods remain the same)\n",
        "\n",
        "    def load_image(self, file_name=None):\n",
        "        if file_name is None:\n",
        "            file_name, _ = QFileDialog.getOpenFileName(self, \"Open Image File\", \"\", \"Images (*.png *.jpg *.bmp)\")\n",
        "\n",
        "        if file_name:\n",
        "            self.current_image = cv2.imread(file_name)\n",
        "            if self.current_image is not None:\n",
        "                self.display_image(self.current_image)\n",
        "                print(f\"Loaded image: {file_name}\")\n",
        "            else:\n",
        "                print(f\"Failed to load image: {file_name}\")\n",
        "\n",
        "    def display_image(self, img):\n",
        "        height, width, channel = img.shape\n",
        "        bytes_per_line = 3 * width\n",
        "        q_img = QImage(img.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()\n",
        "        pixmap = QPixmap.fromImage(q_img)\n",
        "        self.image_label.setPixmap(pixmap.scaled(self.image_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation))\n",
        "\n",
        "    # Step 2: Pass the image through a pre-trained object detection model\n",
        "    def load_yolo_model(self):\n",
        "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def detect_objects(self):\n",
        "        if self.current_image is None:\n",
        "            return\n",
        "\n",
        "        img = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2RGB)\n",
        "        results = self.model(img)\n",
        "\n",
        "        self.annotations = []\n",
        "        for *xyxy, conf, cls in results.xyxy[0]:\n",
        "            x1, y1, x2, y2 = map(int, xyxy)\n",
        "            label = f\"{results.names[int(cls)]} {conf:.2f}\"\n",
        "            self.annotations.append({\"label\": label, \"bbox\": [x1, y1, x2-x1, y2-y1]})\n",
        "\n",
        "        self.draw_annotations()\n",
        "        self.update_annotation_list()\n",
        "\n",
        "    # Step 3: Display predictions in the GUI and provide options for users to edit them\n",
        "    def draw_annotations(self):\n",
        "        if self.current_image is None:\n",
        "            return\n",
        "\n",
        "        annotated_image = self.current_image.copy()\n",
        "        for ann in self.annotations:\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "            cv2.rectangle(annotated_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_image, ann[\"label\"], (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
        "\n",
        "        self.display_image(annotated_image)\n",
        "\n",
        "    def update_annotation_list(self):\n",
        "        self.annotation_list.clear()\n",
        "        for i, ann in enumerate(self.annotations):\n",
        "            self.annotation_list.addItem(f\"{i+1}. {ann['label']}\")\n",
        "\n",
        "    # Step 4: Implement export functionality\n",
        "    def export_annotations(self):\n",
        "        if not self.annotations:\n",
        "            return\n",
        "\n",
        "        file_name, _ = QFileDialog.getSaveFileName(self, \"Save Annotations\", \"\", \"JSON (*.json);;XML (*.xml);;CSV (*.csv)\")\n",
        "        if file_name:\n",
        "            if file_name.endswith('.json'):\n",
        "                self.export_json(file_name)\n",
        "            elif file_name.endswith('.xml'):\n",
        "                self.export_xml(file_name)\n",
        "            elif file_name.endswith('.csv'):\n",
        "                self.export_csv(file_name)\n",
        "\n",
        "    def export_json(self, file_name):\n",
        "        with open(file_name, 'w') as f:\n",
        "            json.dump(self.annotations, f)\n",
        "\n",
        "    def export_xml(self, file_name):\n",
        "        root = ET.Element(\"annotations\")\n",
        "        for ann in self.annotations:\n",
        "            obj = ET.SubElement(root, \"object\")\n",
        "            ET.SubElement(obj, \"label\").text = ann[\"label\"]\n",
        "            bbox = ET.SubElement(obj, \"bndbox\")\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "            ET.SubElement(bbox, \"xmin\").text = str(x)\n",
        "            ET.SubElement(bbox, \"ymin\").text = str(y)\n",
        "            ET.SubElement(bbox, \"xmax\").text = str(x + w)\n",
        "            ET.SubElement(bbox, \"ymax\").text = str(y + h)\n",
        "        tree = ET.ElementTree(root)\n",
        "        tree.write(file_name)\n",
        "\n",
        "    def export_csv(self, file_name):\n",
        "        with open(file_name, 'w', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\"label\", \"x\", \"y\", \"width\", \"height\"])\n",
        "            for ann in self.annotations:\n",
        "                writer.writerow([ann[\"label\"]] + ann[\"bbox\"])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app = QApplication(sys.argv)\n",
        "    window = LabelMaster()\n",
        "\n",
        "    # Load a specific image at startup\n",
        "    window.load_image(\"C:/Users/Lenovo/OneDrive/Pictures\")\n",
        "\n",
        "    window.show()\n",
        "    sys.exit(app.exec_())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq5PLUNZK1v-",
        "outputId": "644067f3-9a9a-458a-8a64-651050f69411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyQt5 in /usr/local/lib/python3.10/dist-packages (5.15.11)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.15 in /usr/local/lib/python3.10/dist-packages (from PyQt5) (12.15.0)\n",
            "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in /usr/local/lib/python3.10/dist-packages (from PyQt5) (5.15.15)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    }
  ]
}